{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "THHpmnELxg3s"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\gonza\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D , Flatten, Activation, Dropout, BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "generator = ImageDataGenerator(validation_split= 0.2, rescale=1./255, horizontal_flip= True, vertical_flip= True, rotation_range= 10, height_shift_range= 0.2, width_shift_range= 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "L_q8KkgJPQE6",
        "outputId": "805c759f-2de3-4d6f-e969-6898b0dedc2c"
      },
      "outputs": [],
      "source": [
        "img = image.load_img(r\"C:\\Users\\gonza\\Downloads\\PokemonData\\Zubat\\3e91e56b8ea045a5b2db1b3eea58cfac.jpg\", target_size= (224,224))\n",
        "x = image.img_to_array(img)\n",
        "x = x.reshape((1,) + x.shape)\n",
        "\n",
        "i = 0\n",
        "for batch in generator.flow(x, batch_size= 1, save_to_dir=r'C:\\Users\\gonza\\Downloads\\PokemonData\\Zubat', save_prefix='Zubat', save_format='jpeg'):\n",
        "\n",
        "    i += 1\n",
        "    if i > 20:\n",
        "        break  # otherwise the generator would loop indefinitely\n",
        "\n",
        "\n",
        "#traindata = generator.flow_from_directory(directory= r\"C:\\Users\\gonza\\Downloads\\PokemonData\", target_size=(224,224), subset = \"training\", seed= 66, keep_aspect_ratio= True, color_mode= \"rgb\")\n",
        "#testdata = generator.flow_from_directory(directory=r\"C:\\Users\\gonza\\Downloads\\PokemonData\", target_size=(224,224), subset = \"validation\", seed = 66, keep_aspect_ratio= True, color_mode= \"rgb\")\n",
        "#traindata.image_shape\n",
        "#traindata.class_indices\n",
        "#np.fromiter(traindata.class_indices.keys(), dtype = str,)\n",
        "#culo = np.array(list(traindata.class_indices.keys()), dtype= str)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(64,padding=\"same\", input_shape=(224, 224, 3), activation=\"relu\", kernel_size= 3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv2D(32,activation=\"relu\", kernel_size= 3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(150, activation=\"softmax\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 224, 224, 64)      256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 224, 224, 64)      0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 222, 222, 32)      18464     \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 222, 222, 32)      128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 222, 222, 32)      0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 111, 111, 32)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 111, 111, 32)      0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 394272)            0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 150)               59140950  \n",
            "                                                                 \n",
            "=================================================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total params: 59161590 (225.68 MB)\n",
            "Trainable params: 59161398 (225.68 MB)\n",
            "Non-trainable params: 192 (768.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 5511 images belonging to 150 classes.\n",
            "Found 1309 images belonging to 150 classes.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "traindata = generator.flow_from_directory(directory= r\"C:\\Users\\gonza\\Downloads\\PokemonData\", target_size=(224,224), subset = \"training\", seed= 66, keep_aspect_ratio= True, color_mode= \"rgb\")\n",
        "testdata = generator.flow_from_directory(directory=r\"C:\\Users\\gonza\\Downloads\\PokemonData\", target_size=(224,224), subset = \"validation\", seed = 66, keep_aspect_ratio= True, color_mode= \"rgb\")\n",
        "\n",
        "#np.fromiter(traindata.class_indices.keys(), dtype = str,)\n",
        "culo = np.array(list(traindata.class_indices.keys()), dtype= str)\n",
        "traindata.batch_size\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "173/173 [==============================] - 267s 2s/step - loss: 120.1968 - accuracy: 0.0256 - val_loss: 16.1243 - val_accuracy: 0.0069\n",
            "Epoch 2/10\n",
            "173/173 [==============================] - 265s 2s/step - loss: 48.1224 - accuracy: 0.0385 - val_loss: 8.9325 - val_accuracy: 0.0298\n",
            "Epoch 3/10\n",
            "173/173 [==============================] - 265s 2s/step - loss: 19.2479 - accuracy: 0.0537 - val_loss: 21.5602 - val_accuracy: 0.0252\n",
            "Epoch 4/10\n",
            "173/173 [==============================] - 265s 2s/step - loss: 5.6856 - accuracy: 0.0726 - val_loss: 7.7886 - val_accuracy: 0.0367\n",
            "Epoch 5/10\n",
            "173/173 [==============================] - 266s 2s/step - loss: 4.2193 - accuracy: 0.1129 - val_loss: 5.2035 - val_accuracy: 0.0657\n",
            "Epoch 6/10\n",
            "173/173 [==============================] - 265s 2s/step - loss: 3.8365 - accuracy: 0.1354 - val_loss: 4.4445 - val_accuracy: 0.1345\n",
            "Epoch 7/10\n",
            "173/173 [==============================] - 265s 2s/step - loss: 3.6152 - accuracy: 0.1617 - val_loss: 4.4151 - val_accuracy: 0.1207\n",
            "Epoch 8/10\n",
            "173/173 [==============================] - 461s 3s/step - loss: 3.4416 - accuracy: 0.1854 - val_loss: 3.5950 - val_accuracy: 0.1673\n",
            "Epoch 9/10\n",
            "173/173 [==============================] - 266s 2s/step - loss: 3.2692 - accuracy: 0.2078 - val_loss: 3.5161 - val_accuracy: 0.1887\n",
            "Epoch 10/10\n",
            "173/173 [==============================] - 265s 2s/step - loss: 3.2528 - accuracy: 0.2248 - val_loss: 4.1633 - val_accuracy: 0.1375\n"
          ]
        }
      ],
      "source": [
        "model.fit(\n",
        "        traindata,\n",
        "        epochs= 10,\n",
        "        validation_data= testdata\n",
        "        , shuffle= True)\n",
        "model.save_weights('first_try.h5')  # always save your weights after training or during training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj43oziGeSx2"
      },
      "source": [
        "https://builtin.com/machine-learning/vgg16\n",
        "\n",
        "https://towardsdatascience.com/transfer-learning-with-vgg16-and-keras-50ea161580b4"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
